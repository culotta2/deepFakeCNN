{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import numpy.random as rn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deepfake = keras.Sequential([\n",
    "  layers.Conv2D(filters = 64, kernel_size = 4, strides = (1, 1), input_shape = (256, 256, 3), padding = 'same', activation = 'relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(filters = 32, kernel_size = 4, strides = (1, 1), padding = 'same', activation = 'relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(filters = 16, kernel_size = 4, strides = (1, 1), padding = 'same', activation = 'relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(units = 4096, activation = 'relu'),\n",
    "  layers.Dropout(rate = 0.1),\n",
    "  layers.Dense(units = 256, activation = 'relu'), \n",
    "  layers.Dense(units = 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deepfake.compile(optimizer = 'adam', \n",
    "                       metrics = keras.metrics.BinaryAccuracy(),\n",
    "                       loss = keras.losses.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 256, 256, 64)      3136      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 128, 128, 64)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 128, 128, 32)      32800     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 64, 64, 16)        8208      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 16384)             0         \n_________________________________________________________________\ndense (Dense)                (None, 4096)              67112960  \n_________________________________________________________________\ndropout (Dropout)            (None, 4096)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               1048832   \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 68,206,193\nTrainable params: 68,206,193\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_deepfake.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second function to randomly select image data from a file\n",
    "def get_images(n: int, dtype: str='train', seed: int=None):\n",
    "    '''\n",
    "    Returns n randomly selected testing, training, or validation data.\n",
    "    \n",
    "    Takes ~13 sec / 100 iter with n = 100\n",
    "    Takes ~118 sec / 1000 iter with n = 100\n",
    "    '''\n",
    "\n",
    "    # Make sure train param is valid\n",
    "    if dtype not in ['train', 'valid', 'test']:\n",
    "        raise Exception(\"dtype argument must be train, valid, or test.\")\n",
    "    \n",
    "    # Load labeled dataframes\n",
    "    PATHDIR = Path('data')\n",
    "    df = pd.read_csv(PATHDIR / f'{dtype}.csv', header = 0).drop(['original_path', 'Unnamed: 0', 'label_str'], axis=1)\n",
    "\n",
    "    \n",
    "    # Get the number of files in the directory of interest\n",
    "    n_files = {\"train\": 50000, \"valid\": 10000, \"test\": 10000}[dtype]\n",
    "    \n",
    "    # Make sure you don't want more pictures than we have\n",
    "    if n > n_files:\n",
    "        raise Exception(f'There are not {n} files in the {dtype} folder')\n",
    "    \n",
    "    # Create the paths to the data\n",
    "    datapath = Path('.') / 'data' / 'real_vs_fake' / 'real-vs-fake' / dtype\n",
    "    fakepath = datapath / 'fake'\n",
    "    realpath = datapath / 'real'\n",
    "    \n",
    "    # Set a seed if present\n",
    "    if seed is not None:\n",
    "        rn.seed(seed)\n",
    "    \n",
    "    # Get n random ids\n",
    "    sample_ids = rn.choice(df['id'].to_numpy(), size=n)\n",
    "    \n",
    "    # Get the labels and image paths from the ids\n",
    "    sample_df = df.copy()\n",
    "    sample_df = sample_df[sample_df['id'].isin(sample_ids)]\n",
    "\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to prepare random images for training\n",
    "def prep_for_train(sample_df):\n",
    "    \"\"\"\n",
    "    Gets the images from the get_image family of functions into a format\n",
    "    that the model can understand.\n",
    "    \"\"\"\n",
    "    # Save the labels\n",
    "    y = sample_df['label'].to_numpy()\n",
    "\n",
    "    # Path to the data\n",
    "    DATADIR = Path('data/') / 'real_vs_fake'/ 'real-vs-fake'\n",
    "\n",
    "    # Load the sample images\n",
    "    n = sample_df.shape[0]\n",
    "    X = np.empty(shape=(n, 256, 256, 3))\n",
    "\n",
    "    # Load in the images to be trained on\n",
    "    for img_idx, img_path in enumerate(sample_df['path']):\n",
    "        img = plt.imread(DATADIR / img_path)\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "        X[img_idx, :, :, :] = img / 255.0\n",
    "\n",
    "    return X, y[np.newaxis].reshape(-1, 1)\n",
    "        "
   ]
  },
  {
   "source": [
    "# TRAIN THAT MODEL!\n",
    "X, y = prep_for_train(get_images(1000, seed=69))\n",
    "model_fit = model_deepfake.fit(X, y, epochs=5, batch_size=50, validation_data=prep_for_train(get_images(100, dtype='valid', seed=12)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 7.9094 - binary_accuracy: 0.4775 - val_loss: 7.3196 - val_binary_accuracy: 0.5200\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 8.0389 - binary_accuracy: 0.4728 - val_loss: 7.3196 - val_binary_accuracy: 0.5200\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 7.9959 - binary_accuracy: 0.4757 - val_loss: 7.3196 - val_binary_accuracy: 0.5200\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 8.1530 - binary_accuracy: 0.4654 - val_loss: 7.3196 - val_binary_accuracy: 0.5200\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 38s 2s/step - loss: 8.0383 - binary_accuracy: 0.4729 - val_loss: 7.3196 - val_binary_accuracy: 0.5200\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-f6b27b303abd>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-f6b27b303abd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .config.list_physical_devices()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 17056259349394787453\n]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing installation: tensorflow 2.4.1\n",
      "Uninstalling tensorflow-2.4.1:\n",
      "  Would remove:\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/estimator_ckpt_converter\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/import_pb_to_tensorboard\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/saved_model_cli\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/tensorboard\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/tf_upgrade_v2\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/tflite_convert\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/toco\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/bin/toco_from_protos\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/lib/python3.8/site-packages/tensorflow-2.4.1.dist-info/*\n",
      "    /home/dom/Documents/School/Stat430/deepFakeCNN/venv/lib/python3.8/site-packages/tensorflow/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0d2a653ea5a11e463c7a5ca7f1200831bd9d8f6e90aec136b3f9ac2ea2b6fabb6",
   "display_name": "Python 3.8.6  ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "d2a653ea5a11e463c7a5ca7f1200831bd9d8f6e90aec136b3f9ac2ea2b6fabb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}