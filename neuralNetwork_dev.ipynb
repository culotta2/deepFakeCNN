{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from pathlib import Path\n",
    "\n",
    "# Helper functions\n",
    "# from helper_functions import imgs_to_numpy\n",
    "\n",
    "# Styles for miles\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GimmeImages(data_split, batch_size = 100):\n",
    "    \n",
    "    DATADIR = Path('data/') / 'real_vs_fake' / 'real-vs-fake' / data_split\n",
    "    \n",
    "    if data_split == \"test\":\n",
    "        imgs = DirectoryIterator(DATADIR,\n",
    "                             image_data_generator = ImageDataGenerator(rescale = 1./255),\n",
    "                             color_mode = 'rgb', \n",
    "                             classes = [\"real\", \"fake\"],\n",
    "                             target_size = (256, 256),\n",
    "                             batch_size = batch_size,\n",
    "                             class_mode = 'binary',\n",
    "                             shuffle = False)\n",
    "    else:\n",
    "        imgs = DirectoryIterator(DATADIR,\n",
    "                                 image_data_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                                                                           horizontal_flip = True,\n",
    "                                                                           rotation_range = 20),\n",
    "                                 color_mode = 'rgb', \n",
    "                                 classes = [\"real\", \"fake\"],\n",
    "                                 target_size = (256, 256),\n",
    "                                 batch_size = batch_size,\n",
    "                                 class_mode = 'binary',\n",
    "                                 shuffle = True)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_imgs = GimmeImages('train')\n",
    "val_imgs   = GimmeImages('valid')\n",
    "test_imgs  = GimmeImages('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deepfake = keras.Sequential([\n",
    "  keras.Input(shape = (256, 256, 3)),\n",
    "  layers.Conv2D(filters = 16, kernel_size = 3, strides = (1, 1), padding = 'same', activation = 'relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(filters = 32, kernel_size = 3, strides = (1, 1), padding = 'same', activation = 'relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(filters = 64, kernel_size = 3, strides = (1, 1), padding = 'same', activation = 'relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(units = 256, activation = 'relu'),\n",
    "  layers.Dropout(rate = 0.1),\n",
    "  layers.Dense(units = 128, activation = 'relu'), \n",
    "  layers.Dense(units = 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_deepfake.compile(optimizer = 'adam', \n",
    "#                       metrics = [keras.metrics.BinaryAccuracy(), \n",
    "#                                  keras.metrics.Precision(), \n",
    "#                                  keras.metrics.Recall()],\n",
    "#                       loss = keras.losses.BinaryCrossentropy(from_logits = True,\n",
    "#                                                              name = 'binary_crossentropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deepfake.compile(optimizer = 'adam', \n",
    "                       metrics = [keras.metrics.BinaryAccuracy()],\n",
    "                       loss = keras.losses.BinaryCrossentropy(from_logits = True,\n",
    "                                                              name = 'binary_crossentropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16777472  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 16,834,081\n",
      "Trainable params: 16,834,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_deepfake.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1000 steps, validate for 200 steps\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1599s 2s/step - loss: 0.5627 - binary_accuracy: 0.6880 - val_loss: 0.4966 - val_binary_accuracy: 0.7301\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 1584s 2s/step - loss: 0.4260 - binary_accuracy: 0.7939 - val_loss: 0.4131 - val_binary_accuracy: 0.8105\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 1620s 2s/step - loss: 0.3496 - binary_accuracy: 0.8400 - val_loss: 0.3341 - val_binary_accuracy: 0.8389\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 1579s 2s/step - loss: 0.3002 - binary_accuracy: 0.8661 - val_loss: 0.2940 - val_binary_accuracy: 0.8738\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 1587s 2s/step - loss: 0.2590 - binary_accuracy: 0.8875 - val_loss: 0.2586 - val_binary_accuracy: 0.8794\n"
     ]
    }
   ],
   "source": [
    "model_fit = model_deepfake.fit(train_imgs,\n",
    "                               epochs = 5,\n",
    "                               validation_data = val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deepFakeModel1/assets\n"
     ]
    }
   ],
   "source": [
    "model_deepfake.save('deepFakeModel1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('deepFakeModel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1000 steps, validate for 200 steps\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 2821s 3s/step - loss: 0.0814 - binary_accuracy: 0.9688 - val_loss: 0.1368 - val_binary_accuracy: 0.9529\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 1860s 2s/step - loss: 0.0787 - binary_accuracy: 0.9699 - val_loss: 0.1395 - val_binary_accuracy: 0.9518\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 2025s 2s/step - loss: 0.0719 - binary_accuracy: 0.9724 - val_loss: 0.1394 - val_binary_accuracy: 0.9463\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 1656s 2s/step - loss: 0.0727 - binary_accuracy: 0.9724 - val_loss: 0.1191 - val_binary_accuracy: 0.9527\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 1605s 2s/step - loss: 0.0697 - binary_accuracy: 0.9732 - val_loss: 0.1133 - val_binary_accuracy: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffed1f0e450>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_imgs,\n",
    "          epochs = 5,\n",
    "          validation_data = val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.0813806891348213,\n",
       "  0.0787137285657227,\n",
       "  0.07186982293240726,\n",
       "  0.07270042353309691,\n",
       "  0.06974298000941052],\n",
       " 'binary_accuracy': [0.96876, 0.96989, 0.97236, 0.97239, 0.97318],\n",
       " 'val_loss': [0.13679828172549605,\n",
       "  0.1394640222284943,\n",
       "  0.13938951111864298,\n",
       "  0.11909030293114484,\n",
       "  0.11332757879979909],\n",
       " 'val_binary_accuracy': [0.9529, 0.95185, 0.94625, 0.9527, 0.95835]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"modelHistEpoch22_26\", model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deepFakeModel1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('deepFakeModel_saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['binary_accuracy'], 'g.-', label = 'Binary Accuracy')\n",
    "plt.plot(model.history.history['val_binary_accuracy'], 'r.-', label = 'Val Binary Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Binary Accuracy over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## James' Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256, 256, 3)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='softmax'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer = SGD(lr = 1e-6), \n",
    "              metrics = [keras.metrics.BinaryAccuracy(), \n",
    "                   keras.metrics.Precision(), \n",
    "                   keras.metrics.Recall()],\n",
    "              loss = keras.losses.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1000 steps, validate for 200 steps\n",
      " 411/1000 [===========>..................] - ETA: 3:40 - loss: 2.1835 - binary_accuracy: 0.5003 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-8df1f2e74938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_fit = model.fit(train_imgs,\n\u001b[1;32m      2\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                       validation_data = val_imgs)\n\u001b[0m",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/apps/anaconda3/envs/wmlce-v1.7.0-py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_imgs,\n",
    "                      epochs = 1,\n",
    "                      validation_data = val_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need 2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.keras.preprocessing' has no attribute 'image_dataset_from_directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-99c35a2ed01f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.keras.preprocessing' has no attribute 'image_dataset_from_directory'"
     ]
    }
   ],
   "source": [
    "tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"data\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path attempts, no need currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images as numpy array\n",
    "for dsplit in ('train', 'valid', 'test'):\n",
    "    imgs_to_numpy(dsplit=dsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['path'].tail()\n",
    "img_path = 'train/fake/73ILM40K3Z.jpg'\n",
    "img_idx = 99999\n",
    "img = plt.imread(DATADIR / img_path)\n",
    "X[img_idx, :, :, :] = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsplit = 'train'\n",
    "\n",
    "# Check that the split exists\n",
    "if dsplit not in ('train', 'valid', 'test'):\n",
    "    raise Exception('dsplit must be `train`, `test`, or `valid`')\n",
    "\n",
    "# Load labeled dataframes\n",
    "PATHDIR = Path('data')\n",
    "DATADIR = Path('data/') / 'real_vs_fake' / 'real-vs-fake'\n",
    "SAVEPATH = PATHDIR / 'data_array'\n",
    "\n",
    "df = pd.read_csv(PATHDIR / f'{dsplit}.csv', header=0).drop(\n",
    "    ['original_path', 'Unnamed: 0', 'label_str'], axis=1)\n",
    "\n",
    "# Create containers for the image data\n",
    "n = df.shape[0]\n",
    "X = np.empty(shape=(n, 256, 256, 3))\n",
    "y = df['label'].to_numpy()[np.newaxis].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[img_idx, :, :, :]\n",
    "with open(SAVEPATH / f'X_{dsplit}.npy', 'wb') as file:\n",
    "    np.save(file, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVEPATH / f'y_{dsplit}.npy', 'wb') as file:\n",
    "        np.save(file, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(n, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the training data\n",
    "PATHTRAIN = Path('data') / 'data_array'\n",
    "with tf.device('/device:GPU:0'):\n",
    "    with open(PATHTRAIN / 'X_train.npy', 'rb') as f:\n",
    "        X = np.load(f)\n",
    "    \n",
    "    with open(PATHTRAIN / 'y_train.npy', 'rb') as f:\n",
    "        y = np.load(f)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "d2a653ea5a11e463c7a5ca7f1200831bd9d8f6e90aec136b3f9ac2ea2b6fabb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
